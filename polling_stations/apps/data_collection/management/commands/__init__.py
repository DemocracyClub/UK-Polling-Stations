"""
Defines the base importer classes to override
"""
import csv
import json
import glob
import os
import re
import shapefile
import tempfile
import unicodedata
import urllib.request
import zipfile

from collections import namedtuple

from django.core.management.base import BaseCommand
from django.contrib.gis import geos
from django.contrib.gis.gdal import DataSource, GDALException
from django.contrib.gis.geos import Point, GEOSGeometry
from django.utils.encoding import force_text
from django.utils.safestring import mark_safe

from councils.models import Council
from data_collection.data_quality_report import (
    DataQualityReportBuilder,
    StationReport,
    DistrictReport,
    ResidentialAddressReport
)
from pollingstations.models import (
    PollingStation,
    PollingDistrict,
    ResidentialAddress
)
from data_collection.models import DataQuality
from addressbase.helpers import create_address_records_for_council


class CsvHelper:

    def __init__(self, filepath, encoding='utf-8', delimiter=','):
        self.filepath = filepath
        self.encoding = encoding
        self.delimiter = delimiter

    def parseCsv(self):
        file = open(self.filepath, 'rt', encoding=self.encoding)
        reader = csv.reader(file, delimiter=self.delimiter)
        header = next(reader)

        # mimic the data structure generated by ffs so existing import
        # scripts don't break
        replace = {
            ' ': '_',
            '.': '_',
            '(': '',
            ')': '',
        }
        clean = []
        for s in header:
            s = s.strip().lower()
            for k, v in replace.items():
                s = s.replace(k, v)
            clean.append(s)
        RowKlass = namedtuple('RowKlass', clean)

        data = []
        for row in map(RowKlass._make, reader):
            data.append(row)

        file.close()
        return data


class BaseImporter(BaseCommand):
    srid = 27700
    districts_srid = None
    council_id = None
    base_folder_path = None
    stations_name = "polling_places"
    districts_name = "polling_districts"
    csv_encoding = 'utf-8'
    csv_delimiter = ','

    def postcode_from_address(self, address):
        return address.split(',')[-1]

    def string_to_newline_addr(self, string):
        return "\n".join(string.split(',')[:-1])

    def get_srid(self, type=None):
        if type == 'districts' and self.districts_srid is not None:
            return self.districts_srid
        else:
            return self.srid

    def clean_poly(self, poly):
        if isinstance(poly, geos.Polygon):
            poly = geos.MultiPolygon(poly, srid=self.get_srid('districts'))
            return poly
        # try:
        #     polygons = wkt[18:-3].split(')), ((')
        #     WKT = ""
        #     for polygon in polygons:
        #         points = polygon.split(',')
        #         cleaned_points = ""
        #         for point in points:
        #             split_points = point.strip().split(' ')
        #             x = split_points[0]
        #             y = split_points[1]
        #             cleaned_points += "%s %s, " % (x,y)
        #         cleaned_points = "((%s))," % cleaned_points[:-2]
        #
        #         WKT += cleaned_points
        # except:
        #     WKT = wkt
        return poly

    def import_data(self):
        """
        There are two types of import - districts and stations.
        """
        self.import_polling_districts()
        self.import_polling_stations()

    def add_polling_district(self, district_info):
        PollingDistrict.objects.update_or_create(
            council=self.council,
            internal_council_id=district_info.get(
                'internal_council_id', 'none'),
            defaults=district_info,
        )

    def add_polling_station(self, station_info):
        PollingStation.objects.update_or_create(
            council=self.council,
            internal_council_id=station_info['internal_council_id'],
            defaults=station_info,
        )

    def import_polling_stations(self):
        stations = os.path.join(self.base_folder_path, self.stations_name)

        helper = CsvHelper(stations, self.csv_encoding, self.csv_delimiter)
        data = helper.parseCsv()
        for row in data:
            station_info = self.station_record_to_dict(row)
            if station_info is None:
                continue
            if 'council' not in station_info:
                station_info['council'] = self.council

            self.add_polling_station(station_info)

    def post_import(self):
        raise NotImplementedError

    def clean_postcodes_overlapping_districts(self):
        data = create_address_records_for_council(self.council)
        self.postcodes_contained_by_district = data['no_attention_needed']
        self.postcodes_with_addresses_generated = data['addresses_created']


    def report(self):
        # build report
        report = DataQualityReportBuilder(self.council_id)
        station_report = StationReport(self.council_id)
        district_report = DistrictReport(self.council_id)
        address_report = ResidentialAddressReport(self.council_id)
        report.build_report()

        # save a static copy in the DB that we can serve up on the website
        record = DataQuality.objects.get_or_create(
            council_id=self.council_id,
        )
        record[0].report = report.generate_string_report()
        record[0].num_stations = station_report.get_stations_imported()
        record[0].num_districts = district_report.get_districts_imported()
        record[0].num_addresses = address_report.get_addresses_imported()
        record[0].save()

        # output to console
        report.output_console_report()

    def handle(self, *args, **kwargs):
        if self.council_id is None:
            self.council_id = args[0]

        self.council = Council.objects.get(pk=self.council_id)

        # Delete old data for this council
        PollingStation.objects.filter(council=self.council).delete()
        PollingDistrict.objects.filter(council=self.council).delete()
        ResidentialAddress.objects.filter(council=self.council).delete()

        if getattr(self, 'local_files', True):
            if self.base_folder_path is None:
                self.base_folder_path = os.path.abspath(
                    glob.glob('data/{0}-*'.format(self.council_id))[0]
                )

        self.import_data()

        # Optional step for post import tasks
        try:
            self.post_import()
        except NotImplementedError:
            pass

        # For areas with shape data, use AddressBase to clean up overlapping
        # postcode
        self.clean_postcodes_overlapping_districts()

        # save and output data quality report
        self.report()


class BaseShpImporter(BaseImporter):
    """
    Import data where districts are shapefiles and stations are csv
    """
    def import_polling_districts(self):
        sf = shapefile.Reader("{0}/{1}".format(
            self.base_folder_path,
            self.districts_name)
        )
        for district in sf.shapeRecords():
            district_info = self.district_record_to_dict(district.record)
            if 'council' not in district_info:
                district_info['council'] = self.council

            geojson = json.dumps(district.shape.__geo_interface__)
            poly = self.clean_poly(
                GEOSGeometry(geojson, srid=self.get_srid('districts')))
            district_info['area'] = poly
            self.add_polling_district(district_info)


class BaseShpShpImporter(BaseShpImporter):
    """
    Import data where both stations and polling districts are
    shapefiles.
    """
    def import_polling_stations(self):
        import_polling_station_shapefiles(self)


def import_polling_station_shapefiles(importer):
    sf = shapefile.Reader("{0}/{1}".format(
        importer.base_folder_path,
        importer.stations_name)
    )
    for station in sf.shapeRecords():
        station_info = importer.station_record_to_dict(station.record)
        if station_info is not None:
            if 'council' not in station_info:
                station_info['council'] = importer.council

            station_info['location'] = Point(
                *station.shape.points[0],
                srid=importer.get_srid())
            importer.add_polling_station(station_info)


class BaseJasonImporter(BaseImporter):
    """
    Import those councils whose data is JASON.
    """

    def import_polling_districts(self):
        districtsfile = os.path.join(
            self.base_folder_path, self.districts_name)
        districts = json.load(open(districtsfile))

        for district in districts['features']:
            district_info = self.district_record_to_dict(district)
            if district_info is not None:
                if 'council' not in district_info:
                    district_info['council'] = self.council

                if district_info is None:
                    continue
                poly = self.clean_poly(
                    GEOSGeometry(json.dumps(district['geometry']),
                                 srid=self.get_srid('districts')))
                district_info['area'] = poly
                self.add_polling_district(district_info)


class BaseKamlImporter(BaseImporter):
    """
    Import those councils whose data is KML
    """

    districts_srid = 4326

    def strip_z_values(self, geojson):
        districts = json.loads(geojson)
        districts['type'] = 'Polygon'
        for points in districts['coordinates'][0][0]:
            if len(points) == 3:
                points.pop()
        districts['coordinates'] = districts['coordinates'][0]
        return json.dumps(districts)

    def district_record_to_dict(self, record):
        geojson = self.strip_z_values(record.geom.geojson)
        poly = self.clean_poly(
            GEOSGeometry(geojson, srid=self.get_srid('districts')))
        return {
            'internal_council_id': record['Name'].value,
            'name': record['Name'].value,
            'area': poly
        }

    def add_kml_district(self, kml):

        try:
            ds = DataSource(kml)
        except GDALException:
            # This is very strainge â€“ sometimes the above will fail the first
            # time, but not the second. Seen on OS X with GDAL 2.2.0
            ds = DataSource(kml)

        lyr = ds[0]
        for feature in lyr:
            district_info = self.district_record_to_dict(feature)
            if 'council' not in district_info:
                district_info['council'] = self.council

            self.add_polling_district(district_info)

    def add_kml_station(self, kml):
        ds = DataSource(kml)
        lyr = ds[0]
        for feature in lyr:
            station_info = self.station_record_to_dict(feature)
            if 'council' not in station_info:
                station_info['council'] = self.council

            self.add_polling_station(station_info)

    def import_polling_districts(self):
        districtsfile = os.path.join(
            self.base_folder_path, self.districts_name)

        if not districtsfile.endswith('.kmz'):
            self.add_kml_district(districtsfile)
            return

        # It's a .kmz file !
        # Because the C lib that the django DataSource is wrapping
        # expects a file on disk, let's extract the actual KML to a tmpfile.
        kmz = zipfile.ZipFile(districtsfile, 'r')
        kmlfile = kmz.open('doc.kml', 'r')

        with tempfile.NamedTemporaryFile() as tmp:
            tmp.write(kmlfile.read())
            self.add_kml_district(tmp.name)
            tmp.close()


class BaseGenericApiImporter:
    srid = 4326
    districts_srid = 4326
    districts_url = None
    stations_url = None
    local_files = False

    def import_data(self):
        # deal with 'stations only' or 'districts only' data
        if self.districts_url is not None:
            self.import_polling_districts()
        if self.stations_url is not None:
            self.import_polling_stations()

    def import_polling_districts(self):
        with tempfile.NamedTemporaryFile() as tmp:
            req = urllib.request.urlretrieve(self.districts_url, tmp.name)
            self.add_districts(tmp.name)
        return

    def import_polling_stations(self):
        with tempfile.NamedTemporaryFile() as tmp:
            req = urllib.request.urlretrieve(self.stations_url, tmp.name)
            self.add_stations(tmp.name)
        return

    def add_districts(self, filename):
        raise NotImplementedError

    def add_stations(self, filename):
        raise NotImplementedError


class BaseApiKmlKmlImporter(BaseGenericApiImporter, BaseKamlImporter):
    def add_districts(self, filename):
        self.add_kml_district(filename)

    def add_stations(self, filename):
        self.add_kml_station(filename)


class BaseAddressCsvImporter(BaseImporter):

    def slugify(self, value):
        """
        Custom slugify function:

        Convert to ASCII.
        Convert characters that aren't alphanumerics, underscores,
        or hyphens to hyphens
        Convert to lowercase.
        Strip leading and trailing whitespace.

        Unfortunately it is necessary to create wheel 2.0 in this situation
        because using django's standard slugify() function means that
        '1/2 Foo Street' and '12 Foo Street' both slugify to '12-foo-street'.
        This ensures that
        '1/2 Foo Street' becomes '1-2-foo-street' and
        '12 Foo Street' becomes '12-foo-street'

        This means we can avoid appending an arbitrary number and minimise
        disruption to the public URL schema if a council provides updated data
        """
        value = force_text(value)
        value = unicodedata.normalize(
            'NFKD', value).encode('ascii', 'ignore').decode('ascii')
        value = re.sub('[^\w\s-]', '-', value).strip().lower()
        return mark_safe(re.sub('[-\s]+', '-', value))

    def get_slug(self, address_info):
        # if we have a uprn, use that as the slug
        if 'uprn' in address_info:
            if address_info['uprn']:
                return address_info['uprn']

        # otherwise build a slug from the other data we have
        return self.slugify(
            "%s-%s-%s-%s" % (
                self.council.pk,
                address_info['polling_station_id'],
                address_info['address'],
                address_info['postcode']
            )
        )

    def add_residential_address(self, address_info):

        """
        strip all whitespace from postcode and convert to uppercase
        this will make it easier to query this based on user-supplied postcode
        """
        address_info['postcode'] =\
            re.sub('[^A-Z0-9]', '', address_info['postcode'].upper())

        # generate a unique slug so we can provide a consistent url
        slug = self.get_slug(address_info)

        ResidentialAddress.objects.update_or_create(
            council=self.council,
            address=address_info['address'],
            postcode=address_info['postcode'],
            polling_station_id=address_info['polling_station_id'],
            slug=slug
        )

    def import_residential_addresses(self):
        addresses = os.path.join(self.base_folder_path, self.addresses_name)

        helper = CsvHelper(addresses, self.csv_encoding, self.csv_delimiter)
        data = helper.parseCsv()
        for row in data:
            address_info = self.address_record_to_dict(row)
            if address_info is None:
                continue
            if 'council' not in address_info:
                address_info['council'] = self.council
            self.add_residential_address(address_info)

    def import_data(self):
        self.import_residential_addresses()
        self.import_polling_stations()
